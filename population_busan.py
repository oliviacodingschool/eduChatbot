import streamlit as st
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import os
st.set_page_config(page_title="μ΄λ“±ν•™μƒ AI μ±—λ΄‡")

@st.cache_resource
def load_model():
    return SentenceTransformer('kykim/bert-kor-base')

model = load_model()

def load_knowledge(file_path="population_busan.txt"):
    if not os.path.exists(file_path):
        return []
    with open(file_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

sentences = load_knowledge()

@st.cache_resource
def build_faiss_index(sentences):
    embeddings = model.encode(sentences)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))
    return index, embeddings

index, embeddings = build_faiss_index(sentences)

st.title("π“ μ΄λ“±ν•™μƒ AI μ±—λ΄‡")
st.markdown("λ‚΄κ°€ λ°°μ΄ μ§€μ‹μΌλ΅λ§ λ€λ‹µν•΄μ”!")

user_input = st.text_input("λ¬΄μ—‡μ΄ κ¶κΈν•κ°€μ”?")
if st.button("μ§λ¬Έν•κΈ°") and user_input:
    query_vec = model.encode([user_input])
    D, I = index.search(np.array(query_vec), k=2)
    best_score = D[0][0]
    matched_answer = sentences[I[0][0]]
    
    if best_score > 500.0:
        st.markdown(f"**μ±—λ΄‡:** μ§λ¬Έμ΄ μ μ΄ν•΄λμ§€ μ•μµλ‹λ‹¤. λ‹¤λ¥Έ λ°©μ‹μΌλ΅ μ§λ¬Έν•΄μ£Όμ„Έμ”. 6Quizλ¥Ό ν™μ©ν•΄λ΄μ”!")
    else:
        st.markdown(f"**μ±—λ΄‡:** {matched_answer}")

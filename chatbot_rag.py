import streamlit as st
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import os
st.set_page_config(page_title="μ΄λ“±ν•™μƒ AI μ±—λ΄‡")

@st.cache_resource
def load_model():
    return SentenceTransformer("jhgan/ko-sbert-sts")

model = load_model()

def load_knowledge(file_path="knowledge.txt"):
    if not os.path.exists(file_path):
        return []
    with open(file_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

sentences = load_knowledge()

@st.cache_resource
def build_faiss_index(sentences):
    embeddings = model.encode(sentences)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))
    return index, embeddings

index, embeddings = build_faiss_index(sentences)

st.title("π“ μ΄λ“±ν•™μƒ AI μ±—λ΄‡")
st.markdown("λ‚΄κ°€ λ°°μ΄ μ§€μ‹μΌλ΅λ§ λ€λ‹µν•΄μ”!")

user_input = st.text_input("λ¬΄μ—‡μ΄ κ¶κΈν•κ°€μ”?")
if st.button("μ§λ¬Έν•κΈ°") and user_input:
    query_vec = model.encode([user_input])
    D, I = index.search(np.array(query_vec), k=2)
    best_score = D[0][0]

    candidate_answers = [sentences[i] for i in I[0]]
    st.markdown(f"**μ±—λ΄‡:** {candidate_answers}")
    
    keywords = ["μΈκµ¬", "μ‚¬λ"]
    matched_answer=None
    for answer in candidate_answers:
        if any(kw in answer for kw in keywords):
            matched_answer = answer
            break
    
    # ν‚¤μ›λ“λ΅ λ§¤μΉ­λ κ² μ—†λ‹¤λ©΄ μ²« λ²μ§Έ ν›„λ³΄ μ‚¬μ©
    if not matched_answer:
        matched_answer = candidate_answers[0]

st.markdown(matched_answer)

if best_score > 500.0:
    st.markdown(f"**μ±—λ΄‡:** μ§λ¬Έμ΄ μ μ΄ν•΄λμ§€ μ•μµλ‹λ‹¤. λ‹¤λ¥Έ λ°©μ‹μΌλ΅ μ§λ¬Έν•΄μ£Όμ„Έμ”. 6Quizλ¥Ό ν™μ©ν•΄λ΄μ”!")
else:
    st.markdown(f"**μ±—λ΄‡:** {matched_answer}")

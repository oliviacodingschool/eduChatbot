import streamlit as st
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import torch
import os

st.set_page_config(page_title="ì¬ìƒì—ë„ˆì§€ AI ì±—ë´‡")

# CUDA ì„¤ì •
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_model():
    model = SentenceTransformer('kykim/bert-kor-base')
    model.to(torch.device(DEVICE))
    return model

model = load_model()

def load_knowledge(file_path="energy2.txt"):
    if not os.path.exists(file_path):
        return []
    with open(file_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

sentences = load_knowledge()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state["history"] = []

# UI
st.title("ğŸŒ± ì¬ìƒì—ë„ˆì§€2 AI ì±—ë´‡")
st.markdown("<h3 style='color:#28a745;'>1ì¸ë‹¹ ë¬¼ ì‚¬ìš©ëŸ‰, ì˜¨ì‹¤ê°€ìŠ¤, íƒ„ì†Œ ë°°ì¶œëŸ‰ ë“±ì— ëŒ€í•´ ì•Œë ¤ë“œë ¤ìš”</h3>", unsafe_allow_html=True)

# ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ì´ˆê¸°í™”"):
    st.session_state["history"] = []
    st.success("ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

user_input = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")

# FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
def build_faiss_index(sentences):
    embeddings = model.encode(sentences, convert_to_numpy=True, device=DEVICE)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))
    return index, sentences

# ì§ˆë¬¸ ì²˜ë¦¬
if st.button("ì§ˆë¬¸í•˜ê¸°") and user_input:
    index, searchable_sentences = build_faiss_index(KNOWLEDGE)

    query_vec = model.encode([user_input], convert_to_numpy=True, device=DEVICE)
    D, I = index.search(np.array(query_vec), k=1)

    if D[0][0] > 500.0:
        matched_answer = "ì˜ ì´í•´ë˜ì§€ ì•Šì•„ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"
    else:
        matched_answer = searchable_sentences[I[0][0]]

    st.markdown(f"**ì±—ë´‡:** {matched_answer}")
    st.session_state["history"].insert(0, (user_input, matched_answer))

# ì´ì „ ì§ˆë¬¸ ê¸°ë¡
if st.session_state["history"]:
    st.markdown("---")
    st.subheader("ğŸ“œ ì´ì „ ì§ˆë¬¸ ê¸°ë¡")
    for idx, (prev_q, prev_a) in enumerate(st.session_state["history"], 1):
        with st.expander(f"Q{idx}: {prev_q}", expanded=False):
            st.markdown(prev_a)

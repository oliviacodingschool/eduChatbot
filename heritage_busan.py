import streamlit as st
import json
from sentence_transformers import SentenceTransformer, util
import torch
import random

# ëª¨ë¸ ë¡œë“œ (ìºì‹±)
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-MiniLM-L6-v2')

model = load_model()

# JSON ë°ì´í„° ë¡œë“œ (ìºì‹±)
@st.cache_data
def load_data():
    with open("busan_heritage.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

heritage_data = load_data()

# Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ›ï¸ ë¶€ì‚° ë¬¸í™”ìœ ì‚° ì±—ë´‡")
question = st.text_input("ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš”. ì¢…ë¥˜, ì‹œëŒ€, ì£¼ì†Œ, ì§€ì •ë‚ ì§œë¥¼ ì•Œ ìˆ˜ ìˆì–´ìš”. ì˜ˆ: 'ì¡°ì„ ì‹œëŒ€ ìœ í˜•ë¬¸í™”ìœ ì‚° ì•Œë ¤ì¤˜'")
search = st.button("ì§ˆë¬¸í•˜ê¸°")

if search:
    if not question:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ì§ˆë¬¸ ë‚´ ì˜ë„ íŒŒì•…
        if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in question:
            filtered_data = [item for item in heritage_data if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        elif "ë¬´í˜•ìœ ì‚°" in question:
            filtered_data = [item for item in heritage_data if "ë¬´í˜•ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        else:
            filtered_data = heritage_data  # ì „ì²´ ê²€ìƒ‰

        if not filtered_data:
            st.error("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¬¸í™”ìœ ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë¬¸ì¥ ë§Œë“¤ê¸°
            sentences = [
                f"{item.get('ì´ë¦„', 'ì´ë¦„ ì—†ìŒ')}ëŠ” {item.get('ì‹œëŒ€', 'ì‹œëŒ€ ì •ë³´ ì—†ìŒ')} ì‹œëŒ€ì˜ {item.get('ì¢…ë¥˜', 'ì¢…ë¥˜ ì •ë³´ ì—†ìŒ')}ì´ë©°, {item.get('ì£¼ì†Œ', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')}ì— ìˆë‹¤."
                for item in filtered_data
            ]

            # ë¬¸ì¥ ì„ë² ë”©
            heritage_embeddings = model.encode(sentences, convert_to_tensor=True)

            # ì§ˆë¬¸ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
            question_embedding = model.encode(question, convert_to_tensor=True)
            scores = util.cos_sim(question_embedding, heritage_embeddings)[0]

            # ìƒìœ„ Nê°œì˜ ìœ ì‚¬ë„ ë†’ì€ í•­ëª©ì„ ì„ íƒ (ì˜ˆ: 5ê°œ)
            top_n = 20
            top_n_indices = torch.topk(scores, top_n).indices.tolist()
            top_n_scores = scores[top_n_indices].tolist()
            top_n_filtered_data = [filtered_data[i] for i in top_n_indices]
            
            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ë¥¼ ì„ íƒ
            selected = random.choice(top_n_filtered_data)
            best_score = max(top_n_scores)  # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ì ìˆ˜
            
            best_index = torch.argmax(scores).item()
            best_score = scores[best_index].item()
            selected = filtered_data[best_index]

            # ê²°ê³¼ ì¶œë ¥
            st.markdown(f"""
### ğŸ·ï¸ {selected['ì´ë¦„']}
- ğŸ“ ì£¼ì†Œ: {selected['ì£¼ì†Œ']}
- ğŸ“œ ì‹œëŒ€: {selected['ì‹œëŒ€'] or 'ì •ë³´ ì—†ìŒ'}
- ğŸ›ï¸ ì¢…ë¥˜: {selected['ì¢…ë¥˜']}
- ğŸ“… ì§€ì • ë‚ ì§œ: {selected.get('ì§€ì •ë‚ ì§œ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ“ ìˆ˜ëŸ‰/ë©´ì : {selected.get('ìˆ˜ëŸ‰/ë©´ì ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ‘¤ ì†Œìœ ì: {selected.get('ì†Œìœ ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ› ï¸ ê´€ë¦¬ì: {selected.get('ê´€ë¦¬ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ” ìœ ì‚¬ë„ ì ìˆ˜: `{best_score:.2f}`
""")

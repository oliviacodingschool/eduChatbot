import streamlit as st
import json
from sentence_transformers import SentenceTransformer, util
import torch

# ëª¨ë¸ ë¡œë“œ (ìºì‹±í•˜ì—¬ ì†ë„ ê°œì„ )
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-MiniLM-L6-v2')

model = load_model()

# JSON ë°ì´í„° ë¡œë”©
@st.cache_data
def load_data():
    with open("busan_heritage.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

heritage_data = load_data()

# ì„¤ëª… ì—†ì´ ë¬¸ì¥ ë§Œë“¤ê¸°
sentences = []
for item in heritage_data:
    name = item.get('ì´ë¦„', 'ì´ë¦„ ì—†ìŒ')
    era = item.get('ì‹œëŒ€', 'ì‹œëŒ€ ì •ë³´ ì—†ìŒ')
    kind = item.get('ì¢…ë¥˜', 'ì¢…ë¥˜ ì •ë³´ ì—†ìŒ')
    addr = item.get('ì£¼ì†Œ', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')
    sent = f"{name}ëŠ” {era} ì‹œëŒ€ì˜ {kind}ì´ë©°, {addr}ì— ìˆë‹¤."
    sentences.append(sent)

# ë¬¸ì¥ ì„ë² ë”©
heritage_embeddings = model.encode(sentences, convert_to_tensor=True)

# Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ›ï¸ ë¶€ì‚° ë¬¸í™”ìœ ì‚° ì±—ë´‡")
question = st.text_input("ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš”. ì˜ˆ: 'ì¡°ì„ ì‹œëŒ€ ë¬¸í™”ìœ ì‚° ì•Œë ¤ì¤˜'")

if question:
    question_embedding = model.encode(question, convert_to_tensor=True)
    scores = util.cos_sim(question_embedding, heritage_embeddings)[0]
    best_index = torch.argmax(scores).item()
    best_score = scores[best_index].item()
    selected = heritage_data[best_index]

    st.markdown(f"""
### ğŸ·ï¸ {selected['ì´ë¦„']}
- ğŸ“ ì£¼ì†Œ: {selected['ì£¼ì†Œ']}
- ğŸ“œ ì‹œëŒ€: {selected['ì‹œëŒ€'] or 'ì •ë³´ ì—†ìŒ'}
- ğŸ›ï¸ ì¢…ë¥˜: {selected['ì¢…ë¥˜']}
- ğŸ“… ì§€ì • ë‚ ì§œ: {selected.get('ì§€ì •ë‚ ì§œ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ“ ìˆ˜ëŸ‰/ë©´ì : {selected.get('ìˆ˜ëŸ‰/ë©´ì ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ‘¤ ì†Œìœ ì: {selected.get('ì†Œìœ ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ› ï¸ ê´€ë¦¬ì: {selected.get('ê´€ë¦¬ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ” ìœ ì‚¬ë„ ì ìˆ˜: `{best_score:.2f}`
""")

import streamlit as st
import json
from sentence_transformers import SentenceTransformer, util
import torch
import random

# ëª¨ë¸ ë¡œë“œ (ìºì‹±)
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-MiniLM-L6-v2')

model = load_model()

# JSON ë°ì´í„° ë¡œë“œ (ìºì‹±)
@st.cache_data
def load_data():
    with open("busan_heritage.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

heritage_data = load_data()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "shown_names" not in st.session_state:
    st.session_state["shown_names"] = []

# êµ¬ ë¦¬ìŠ¤íŠ¸
districts = ['ë™ë˜êµ¬', 'ì‚¬í•˜êµ¬', 'ê¸ˆì •êµ¬', 'ì„œêµ¬', 'ë¶êµ¬', 'ìˆ˜ì˜êµ¬', 'ë¶€ì‚°ì§„êµ¬', 'ê°•ì„œêµ¬',
             'ë‚¨êµ¬', 'ì˜ë„êµ¬', 'ê¸°ì¥êµ°', 'ì‚¬ìƒêµ¬', 'í•´ìš´ëŒ€êµ¬', 'ë™êµ¬']

# Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ›ï¸ ë¶€ì‚° ë¬¸í™”ìœ ì‚° ì±—ë´‡")
question = st.text_input("ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš”. ì˜ˆ: 'ì¡°ì„ ì‹œëŒ€ í•´ìš´ëŒ€êµ¬ ìœ í˜•ë¬¸í™”ìœ ì‚° ì•Œë ¤ì¤˜'")
search = st.button("ì§ˆë¬¸í•˜ê¸°")

if search:
    if not question:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # 1ì°¨ í•„í„°ë§: ì´ì „ì— ë³´ì—¬ì¤€ í•­ëª© ì œì™¸
        filtered_data = [
            item for item in heritage_data 
            if item.get("ì´ë¦„") not in st.session_state["shown_names"]
        ]

        # 2ì°¨ í•„í„°ë§: ì¢…ë¥˜ ê¸°ë°˜
        if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in question:
            filtered_data = [item for item in filtered_data if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        elif "ë¬´í˜•ìœ ì‚°" in question or "ë¬´í˜•ë¬¸í™”ìœ ì‚°" in question:
            filtered_data = [item for item in filtered_data if "ë¬´í˜•ìœ ì‚°" in item.get("ì¢…ë¥˜", "") or "ë¬´í˜•ë¬¸í™”ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        
        # 3ì°¨ í•„í„°ë§: ì£¼ì†Œ ê¸°ë°˜
        selected_districts = [d for d in districts if d in question]
        if selected_districts:
            filtered_data = [item for item in filtered_data if any(d in item.get("ì£¼ì†Œ", "") for d in selected_districts)]

        if not filtered_data:
            st.error("ë” ì´ìƒ ì¡°ê±´ì— ë§ëŠ” ìƒˆë¡œìš´ ë¬¸í™”ìœ ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë¬¸ì¥ ìƒì„±
            sentences = [
                f"{item.get('ì´ë¦„', 'ì´ë¦„ ì—†ìŒ')}ëŠ” {item.get('ì‹œëŒ€', 'ì‹œëŒ€ ì •ë³´ ì—†ìŒ')} ì‹œëŒ€ì˜ {item.get('ì¢…ë¥˜', 'ì¢…ë¥˜ ì •ë³´ ì—†ìŒ')}ì´ë©°, {item.get('ì£¼ì†Œ', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')}ì— ìˆë‹¤."
                for item in filtered_data
            ]

            # ì„ë² ë”© ë¹„êµ
            heritage_embeddings = model.encode(sentences, convert_to_tensor=True)
            question_embedding = model.encode(question, convert_to_tensor=True)
            scores = util.cos_sim(question_embedding, heritage_embeddings)[0]

            # ìƒìœ„ Nê°œ ì¤‘ ë¬´ì‘ìœ„
            top_n = min(20, len(scores))
            top_n_indices = torch.topk(scores, top_n).indices.tolist()
            top_n_filtered_data = [filtered_data[i] for i in top_n_indices]
            top_n_scores = [scores[i].item() for i in top_n_indices]

            # ëœë¤ ì„ íƒ
            combined = list(zip(top_n_filtered_data, top_n_scores))
            random.shuffle(combined)
            selected, best_score = combined[0]

            # ì´ì „ì— ë³´ì—¬ì¤€ ì´ë¦„ ê¸°ë¡
            st.session_state["shown_names"].append(selected["ì´ë¦„"])

            # ì¶œë ¥
            st.markdown(f"""
### ğŸ·ï¸ {selected['ì´ë¦„']}
- ğŸ“ ì£¼ì†Œ: {selected['ì£¼ì†Œ']}
- ğŸ“œ ì‹œëŒ€: {selected['ì‹œëŒ€'] or 'ì •ë³´ ì—†ìŒ'}
- ğŸ›ï¸ ì¢…ë¥˜: {selected['ì¢…ë¥˜']}
- ğŸ“… ì§€ì • ë‚ ì§œ: {selected.get('ì§€ì •ë‚ ì§œ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ“ ìˆ˜ëŸ‰/ë©´ì : {selected.get('ìˆ˜ëŸ‰/ë©´ì ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ‘¤ ì†Œìœ ì: {selected.get('ì†Œìœ ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ› ï¸ ê´€ë¦¬ì: {selected.get('ê´€ë¦¬ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ” ìœ ì‚¬ë„ ì ìˆ˜: `{best_score:.2f}`
""")

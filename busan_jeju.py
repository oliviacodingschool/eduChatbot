import streamlit as st
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import torch
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì œì£¼AIì±—ë´‡")
st.title("ğŸŒ± 4í•™ë…„1ë°˜ ì œì£¼ AIì±—ë´‡!")
st.markdown("<h3 style='color:#28a745;'>ì œì£¼ë„ì˜ ì§€ë¦¬ì •ë³´ë¥¼ ì•Œë ¤ë“œë ¤ìš”!</h3>", unsafe_allow_html=True)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ìš°ì„ )
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ëª¨ë¸ ìºì‹± ë¡œë”©
@st.cache_resource
def load_model():
    model = SentenceTransformer('jhgan/ko-sbert-sts')
    model.to(torch.device(DEVICE))
    return model

model = load_model()

# ì§€ì‹ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_knowledge(file_path):
    if not os.path.exists(file_path):
        return []
    with open(file_path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

# ì§€ì‹ íŒŒì¼ ê²½ë¡œ
file_path = "energy3.txt"
sentences = load_knowledge(file_path)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state["history"] = []

# ì´ˆê¸°í™” ë²„íŠ¼
if st.button("ì´ˆê¸°í™”"):
    st.session_state["history"] = []
    st.success("ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
user_input = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")

# FAISS ì¸ë±ìŠ¤ êµ¬ì¶• í•¨ìˆ˜
def build_faiss_index(sentences):
    embeddings = model.encode(sentences, convert_to_numpy=True, device=DEVICE)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))
    return index, sentences

# ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
if st.button("ì§ˆë¬¸í•˜ê¸°") and user_input:

    # 1. í‚¤ì›Œë“œ ì¡°ê±´ ìš°ì„  ë‹µë³€
    if "1ì¸ë‹¹" in user_input and "ì˜¨ì‹¤ê°€ìŠ¤" in user_input:
        matched_answer = sentences[1] if len(sentences) > 1 else "ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”."
    elif "ì„¸ê³„" in user_input and "ì˜¨ì‹¤ê°€ìŠ¤" in user_input:
        matched_answer = sentences[3] if len(sentences) > 3 else "ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”."
    else:
        # 2. FAISSë¥¼ í†µí•œ ë¬¸ì¥ ìœ ì‚¬ë„ ê²€ìƒ‰
        index, searchable_sentences = build_faiss_index(sentences)
        query_vec = model.encode([user_input], convert_to_numpy=True, device=DEVICE)
        D, I = index.search(np.array(query_vec), k=1)

        # 3. ìœ ì‚¬ë„ ê±°ë¦¬ ê¸°ì¤€ ì„¤ì • (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
        distance = D[0][0]
        if distance > 500.0:
            matched_answer = "ì˜ ì´í•´ë˜ì§€ ì•Šì•„ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"
        else:
            matched_answer = searchable_sentences[I[0][0]]

    # ë‹µë³€ ì¶œë ¥ ë° ê¸°ë¡ ì €ì¥
    st.markdown(f"**ì±—ë´‡:** {matched_answer}")
    st.session_state["history"].insert(0, (user_input, matched_answer))

# ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ ì¶œë ¥
if st.session_state["history"]:
    st.markdown("---")
    st.subheader("ğŸ“œ ì´ì „ ì§ˆë¬¸ ê¸°ë¡")
    for idx, (prev_q, prev_a) in enumerate(st.session_state["history"], 1):
        with st.expander(f"Q{idx}: {prev_q}", expanded=False):
            st.markdown(prev_a)

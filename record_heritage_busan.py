import streamlit as st
import json
from sentence_transformers import SentenceTransformer, util
import torch
import random

# ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-MiniLM-L6-v2')

model = load_model()

# JSON ë°ì´í„° ë¡œë“œ
@st.cache_data
def load_data():
    with open("busan_heritage.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

heritage_data = load_data()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []

# íƒ€ì´í‹€
st.title("ğŸ›ï¸ ë¶€ì‚° ë¬¸í™”ìœ ì‚° ì±—ë´‡")

question = st.text_input("ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš”. ì˜ˆ: 'ì¡°ì„ ì‹œëŒ€ ìœ í˜•ë¬¸í™”ìœ ì‚° ì•Œë ¤ì¤˜'")
search = st.button("ì§ˆë¬¸í•˜ê¸°")

if search:
    if not question:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # í•„í„°ë§: ì¢…ë¥˜ ì¡°ê±´
        if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in question:
            filtered_data = [item for item in heritage_data if "ìœ í˜•ë¬¸í™”ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        elif "ë¬´í˜•ìœ ì‚°" in question:
            filtered_data = [item for item in heritage_data if "ë¬´í˜•ìœ ì‚°" in item.get("ì¢…ë¥˜", "")]
        else:
            filtered_data = heritage_data

        # ì£¼ì†Œ ì¡°ê±´ì´ ìˆë‹¤ë©´ í•„í„°ë§
        areas = ['ë™ë˜êµ¬', 'ì‚¬í•˜êµ¬', 'ê¸ˆì •êµ¬', 'ì„œêµ¬', 'ë¶êµ¬', 'ìˆ˜ì˜êµ¬', 'ë¶€ì‚°ì§„êµ¬', 'ê°•ì„œêµ¬',
                 'ë‚¨êµ¬', 'ì˜ë„êµ¬', 'ê¸°ì¥êµ°', 'ì‚¬ìƒêµ¬', 'í•´ìš´ëŒ€êµ¬', 'ë™êµ¬']
        area_matches = [area for area in areas if area in question]
        if area_matches:
            filtered_data = [item for item in filtered_data if any(area in item.get("ì£¼ì†Œ", "") for area in area_matches)]

        if not filtered_data:
            st.error("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¬¸í™”ìœ ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë¬¸ì¥ ìƒì„±
            sentences = [
                f"{item.get('ì´ë¦„', 'ì´ë¦„ ì—†ìŒ')}ëŠ” {item.get('ì‹œëŒ€', 'ì‹œëŒ€ ì •ë³´ ì—†ìŒ')} ì‹œëŒ€ì˜ {item.get('ì¢…ë¥˜', 'ì¢…ë¥˜ ì •ë³´ ì—†ìŒ')}ì´ë©°, {item.get('ì£¼ì†Œ', 'ì£¼ì†Œ ì •ë³´ ì—†ìŒ')}ì— ìˆë‹¤."
                for item in filtered_data
            ]

            # ì„ë² ë”© ê³„ì‚°
            heritage_embeddings = model.encode(sentences, convert_to_tensor=True)
            question_embedding = model.encode(question, convert_to_tensor=True)
            scores = util.cos_sim(question_embedding, heritage_embeddings)[0]

            # ìƒìœ„ 20ê°œ ì¶”ì¶œ
            top_n = 20
            top_n_indices = torch.topk(scores, top_n).indices.tolist()
            top_n_filtered_data = [filtered_data[i] for i in top_n_indices]
            top_n_scores = [scores[i].item() for i in top_n_indices]

            # ëœë¤ ì„ íƒ
            combined = list(zip(top_n_filtered_data, top_n_scores))
            random.shuffle(combined)
            selected, best_score = combined[0]

            # ê¸°ë¡ ì €ì¥
            st.session_state.history.append({
                "ì§ˆë¬¸": question,
                "ë‹µë³€": selected,
                "ìœ ì‚¬ë„": best_score
            })

# ê¸°ë¡ ë³´ì—¬ì£¼ê¸° (ìµœì‹  ê²ƒì´ ìœ„ì— ì˜¤ë„ë¡)
for record in reversed(st.session_state.history):
    st.markdown(f"""
### ğŸ§¾ ì§ˆë¬¸: {record['ì§ˆë¬¸']}
#### ğŸ·ï¸ {record['ë‹µë³€']['ì´ë¦„']}
- ğŸ“ ì£¼ì†Œ: {record['ë‹µë³€']['ì£¼ì†Œ']}
- ğŸ“œ ì‹œëŒ€: {record['ë‹µë³€'].get('ì‹œëŒ€', 'ì •ë³´ ì—†ìŒ')}
- ğŸ›ï¸ ì¢…ë¥˜: {record['ë‹µë³€'].get('ì¢…ë¥˜', 'ì •ë³´ ì—†ìŒ')}
- ğŸ“… ì§€ì • ë‚ ì§œ: {record['ë‹µë³€'].get('ì§€ì •ë‚ ì§œ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ“ ìˆ˜ëŸ‰/ë©´ì : {record['ë‹µë³€'].get('ìˆ˜ëŸ‰/ë©´ì ', 'ì •ë³´ ì—†ìŒ')}
- ğŸ‘¤ ì†Œìœ ì: {record['ë‹µë³€'].get('ì†Œìœ ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ› ï¸ ê´€ë¦¬ì: {record['ë‹µë³€'].get('ê´€ë¦¬ì', 'ì •ë³´ ì—†ìŒ')}
- ğŸ” ìœ ì‚¬ë„ ì ìˆ˜: `{record['ìœ ì‚¬ë„']:.2f}`
---
""")
